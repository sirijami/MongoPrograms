package FixedLengthInputFormatPackage;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.BytesWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.compress.CompressionCodec;
import org.apache.hadoop.io.compress.CompressionCodecFactory;
import org.apache.hadoop.mapreduce.InputSplit;
import org.apache.hadoop.mapreduce.JobContext;
import org.apache.hadoop.mapreduce.RecordReader;
import org.apache.hadoop.mapreduce.TaskAttemptContext;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.FixedLengthRecordReader;

public class FixedLengthInputFormat extends FileInputFormat<LongWritable, BytesWritable> {
	
	 public static final String FIXED_RECORD_LENGTH = "fixedlengthinputformat.record.length"; 
	 
     public static void setRecordLength(Configuration conf, int recordLength) {
       conf.setInt(FIXED_RECORD_LENGTH, recordLength);
      }
     
     public static int getRecordLength(Configuration conf) {
            return conf.getInt(FIXED_RECORD_LENGTH, 10);
      }

         
     @Override
     public RecordReader<LongWritable, BytesWritable>createRecordReader(InputSplit split, TaskAttemptContext context)
             throws IOException, InterruptedException {
            int recordLength = getRecordLength(context.getConfiguration());
            if (recordLength <= 0) {
             throw new IOException("Fixed record length " + recordLength
                  + " is invalid.  It should be set to a value greater than zero");
           }
            return new FixedLengthRecordReader(10);
      }
       
      @Override
      protected boolean isSplitable(JobContext context, Path file) {
           final CompressionCodec codec = 
                new CompressionCodecFactory(context.getConfiguration()).getCodec(file);
            return (null == codec);
      }


}
